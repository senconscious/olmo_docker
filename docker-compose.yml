name: loki
services:
  olmo:
    build: 
      dockerfile: Dockerfile.olmo
    volumes:
      - ./models/olmo/:/app/models/
      - ./.bash_aliases:/root/.bash_aliases
    environment:
      - LLAMA_CPP_DIR=/app
      - HF_OLMO_LINK=https://huggingface.co/mradermacher/OLMo-1.7-7B-hf-GGUF/resolve/main/OLMo-1.7-7B-hf.Q8_0.gguf
      - OLMO_FILE_NAME=OLMo-1.7-7B-hf.Q8_0.gguf
  llama:
    build:
      dockerfile: Dockerfile.llama
    ports:
      - 8081:8080
    volumes:
      - ./models/llama/:/models/
  qwen2:
    build:
      dockerfile: Dockerfile.qwen2
    ports:
      - 8082:8080
    volumes:
      - ./models/qwen2/:/models/
  gpt2:
    build:
      dockerfile: Dockerfile.gpt2
    ports:
      - 8083:8080
    volumes:
      - ./models/gpt2/:/models/
  zephyr:
    build:
      dockerfile: Dockerfile.zephyr
    ports:
      - 8084:8080
    volumes:
      - ./models/zephyr/:/models/
  phi3:
    build:
      dockerfile: Dockerfile.phi3
    ports:
      - 8085:8080
    volumes:
      - ./models/phi3/:/models/
  stable_diffusion:
    build:
      dockerfile: Dockerfile.stable_diffusion
    environment:
      - PHX_SERVER=true
    ports:
      - 8086:4000
    volumes:
      - ./models/stable_diffusion/:/models/
  whisper:
    build:
      dockerfile: Dockerfile.whisper
    ports:
      - 8087:8080
    volumes:
      - ./models/whisper/:/models/

    
